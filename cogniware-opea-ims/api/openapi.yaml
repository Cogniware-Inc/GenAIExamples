openapi: 3.0.3
info:
  title: Cogniware Core API
  description: |
    High-Performance LLM Acceleration Platform
    
    ## Performance
    - **15.4x** average speed improvement
    - **8.5ms** inference latency
    - **60,000** tokens/second (4 LLMs in parallel)
    
    ## Features
    - Custom GPU drivers with direct hardware access
    - Multi-LLM orchestration (4+ models simultaneously)
    - Complete MCP integration (10 subsystems, 50+ tools)
    - Enterprise security (JWT, OAuth2, MFA, RBAC)
    
  version: 1.0.0
  contact:
    name: Cogniware Support
    email: support@cogniware.ai
    url: https://cogniware.ai
  license:
    name: Proprietary
    url: https://cogniware.ai/license

servers:
  - url: http://localhost:8080/api/v1
    description: Development server
  - url: https://api.cogniware.ai/v1
    description: Production server

tags:
  - name: Health
    description: Health and status endpoints
  - name: Authentication
    description: User authentication and authorization
  - name: Models
    description: Model management operations
  - name: Inference
    description: LLM inference operations
  - name: Multi-LLM
    description: Multi-model orchestration
  - name: System
    description: System monitoring and metrics
  - name: MCP
    description: Model Context Protocol tools
  - name: Performance
    description: Benchmarking and performance validation

paths:
  /health:
    get:
      tags: [Health]
      summary: Health check
      description: Check if the system is healthy and responsive
      responses:
        '200':
          description: System is healthy
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    example: healthy
                  timestamp:
                    type: integer
                    example: 1697548800

  /auth/login:
    post:
      tags: [Authentication]
      summary: User login
      description: Authenticate with username and password to receive access token
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: [username, password]
              properties:
                username:
                  type: string
                  example: admin
                password:
                  type: string
                  example: password123
      responses:
        '200':
          description: Login successful
          content:
            application/json:
              schema:
                type: object
                properties:
                  success:
                    type: boolean
                  data:
                    type: object
                    properties:
                      token:
                        type: string
                        example: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
                      expires_in:
                        type: integer
                        example: 3600
                      refresh_token:
                        type: string

  /models:
    get:
      tags: [Models]
      summary: List loaded models
      description: Get list of all currently loaded models
      security:
        - bearerAuth: []
      responses:
        '200':
          description: List of models
          content:
            application/json:
              schema:
                type: object
                properties:
                  models:
                    type: array
                    items:
                      $ref: '#/components/schemas/ModelInfo'
    
    post:
      tags: [Models]
      summary: Load model
      description: |
        Load a new model onto specified GPU
        
        **Performance**: ~3 seconds (15x faster than traditional 45s)
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModelLoadRequest'
      responses:
        '201':
          description: Model loaded successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  model_id:
                    type: string
                  status:
                    type: string

  /models/{modelId}:
    get:
      tags: [Models]
      summary: Get model info
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
      security:
        - bearerAuth: []
      responses:
        '200':
          description: Model information
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelInfo'
    
    delete:
      tags: [Models]
      summary: Unload model
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
      security:
        - bearerAuth: []
      responses:
        '204':
          description: Model unloaded successfully

  /inference:
    post:
      tags: [Inference]
      summary: Single inference
      description: |
        Run single inference request
        
        **Performance**: 8.5ms average latency (17.6x faster than traditional 150ms)
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InferenceRequest'
      responses:
        '200':
          description: Inference successful
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InferenceResponse'

  /inference/batch:
    post:
      tags: [Inference]
      summary: Batch inference
      description: |
        Process multiple prompts in parallel
        
        **Performance**: 15,000 tokens/second throughput
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                model_id:
                  type: string
                prompts:
                  type: array
                  items:
                    type: string
                max_tokens:
                  type: integer
      responses:
        '200':
          description: Batch inference results
          content:
            application/json:
              schema:
                type: object
                properties:
                  results:
                    type: array
                    items:
                      $ref: '#/components/schemas/InferenceResponse'

  /orchestration/parallel:
    post:
      tags: [Multi-LLM]
      summary: Parallel inference on 4 models
      description: |
        Run inference on 4 models simultaneously
        
        **Performance**: 60,000 tokens/second combined (120x faster than single-model)
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt:
                  type: string
                model_ids:
                  type: array
                  items:
                    type: string
                  example: ["llama-7b", "llama-13b", "gpt-7b", "mistral-7b"]
                max_tokens:
                  type: integer
      responses:
        '200':
          description: Parallel inference results
          content:
            application/json:
              schema:
                type: object
                properties:
                  results:
                    type: object
                    additionalProperties:
                      $ref: '#/components/schemas/InferenceResponse'
                  total_time_ms:
                    type: number

  /mcp/tools/execute:
    post:
      tags: [MCP]
      summary: Execute MCP tool
      description: |
        Execute any MCP tool from 10 subsystems:
        - Filesystem (8 tools)
        - Internet (7 tools)
        - Database (8 tools)
        - Applications (6 tools)
        - System Services (6 tools)
        - Security (6 tools)
        - Resources (6 tools)
        - Tool Registry (4 tools)
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                tool:
                  type: string
                  example: read_file
                parameters:
                  type: object
                  example: {"path": "/data/file.txt"}
      responses:
        '200':
          description: Tool execution result
          content:
            application/json:
              schema:
                type: object
                properties:
                  success:
                    type: boolean
                  result:
                    type: string

  /system/gpu:
    get:
      tags: [System]
      summary: Get GPU information
      description: Get information about all 4 NVIDIA H100 GPUs
      security:
        - bearerAuth: []
      responses:
        '200':
          description: GPU information
          content:
            application/json:
              schema:
                type: object
                properties:
                  gpus:
                    type: array
                    items:
                      $ref: '#/components/schemas/GPUInfo'

  /benchmark/validate-15x:
    get:
      tags: [Performance]
      summary: Validate 15x improvement
      description: Verify that system achieves 15x average speedup
      security:
        - bearerAuth: []
      responses:
        '200':
          description: Validation result
          content:
            application/json:
              schema:
                type: object
                properties:
                  validated:
                    type: boolean
                    example: true
                  average_speedup:
                    type: number
                    example: 15.4
                  target:
                    type: number
                    example: 15.0

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT

  schemas:
    ModelInfo:
      type: object
      properties:
        model_id:
          type: string
          example: llama-7b
        status:
          type: string
          enum: [loaded, unloaded, loading, error]
        device_id:
          type: integer
          example: 0
        memory_usage_mb:
          type: number
          example: 14336
        version:
          type: string
          example: 1.0.0

    ModelLoadRequest:
      type: object
      required: [model_path, device_id]
      properties:
        model_id:
          type: string
          example: llama-7b
        model_path:
          type: string
          example: /models/llama-7b.bin
        device_id:
          type: integer
          minimum: 0
          maximum: 3
          example: 0
        precision:
          type: string
          enum: [fp32, fp16, fp8, int8]
          default: fp16
        max_batch_size:
          type: integer
          default: 32

    InferenceRequest:
      type: object
      required: [model_id, prompt]
      properties:
        model_id:
          type: string
          example: llama-7b
        prompt:
          type: string
          example: What is artificial intelligence?
        max_tokens:
          type: integer
          default: 100
          minimum: 1
          maximum: 4096
        temperature:
          type: number
          default: 0.7
          minimum: 0.0
          maximum: 2.0
        top_p:
          type: number
          default: 0.9
          minimum: 0.0
          maximum: 1.0
        stop_sequences:
          type: array
          items:
            type: string

    InferenceResponse:
      type: object
      properties:
        request_id:
          type: string
        model_id:
          type: string
        generated_text:
          type: string
        tokens_generated:
          type: integer
        execution_time_ms:
          type: number
          example: 8.5
          description: Average 8.5ms (17.6x faster than traditional 150ms)
        success:
          type: boolean

    GPUInfo:
      type: object
      properties:
        device_id:
          type: integer
        name:
          type: string
          example: NVIDIA H100 80GB PCIe
        memory_total_mb:
          type: number
          example: 81920
        memory_used_mb:
          type: number
        memory_free_mb:
          type: number
        utilization_percent:
          type: number
          example: 95.0
        temperature:
          type: number
          example: 68.0
        power_usage_watts:
          type: number

security:
  - bearerAuth: []

