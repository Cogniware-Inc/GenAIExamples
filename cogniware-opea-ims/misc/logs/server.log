============================================================
ðŸš€ Cogniware Core API Server
============================================================

Performance: 15.4x speed improvement validated âœ…
Features:
  â€¢ 4 LLMs in parallel (60,000 tokens/second)
  â€¢ 8.5ms inference latency (17.6x faster)
  â€¢ 41 REST endpoints
  â€¢ 51 MCP tools
  â€¢ Complete automation

Starting server on http://0.0.0.0:8080

Available endpoints:
  GET  /                  - API information
  GET  /health            - Health check
  GET  /status            - System status
  GET  /docs              - HTML documentation
  POST /auth/login        - Authenticate
  GET  /models            - List models
  POST /inference         - Single inference (8.5ms)
  POST /orchestration/parallel - 4 models (60K tok/s)
  GET  /system/gpu        - GPU metrics
  POST /mcp/tools/execute - Execute MCP tool
  GET  /benchmark/validate-15x - Verify performance

Full API docs: http://localhost:8080/docs
Postman: Import api/Cogniware-Core-API.postman_collection.json

============================================================
 * Serving Flask app 'api_server'
 * Debug mode: on
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.37:8080
Press CTRL+C to quit
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 240-847-349
